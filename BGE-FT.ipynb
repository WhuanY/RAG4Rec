{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".inter\n",
    "(g, j, s)\n",
    "g.info <- .udoc\n",
    "j.info <- .idoc\n",
    "\n",
    "g.strRep -> C \n",
    "            o          M\n",
    "            n --BGE--> L ---> out\n",
    "            c --BGE--> P ---> put\n",
    "            a          s\n",
    "j.strRep -> t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuyuhuan/anaconda3/envs/recbole/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wuyuhuan/anaconda3/envs/recbole/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647406761/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2025-01-11 00:17:54,513 - INFO - Usable GPU: 9\n",
      "2025-01-11 00:18:03,475 - INFO - Dataset train Loaded. Shape: (511515, 7)\n",
      "2025-01-11 00:18:03,478 - INFO - Tokenizing train Dataset\n",
      "Tokenizing train Dataset: 100%|██████████| 512/512 [07:43<00:00,  1.10it/s]\n",
      "2025-01-11 00:25:48,374 - INFO - Dataset valid Loaded. Shape: (63950, 7)\n",
      "2025-01-11 00:25:48,375 - INFO - Tokenizing valid Dataset\n",
      "Tokenizing valid Dataset: 100%|██████████| 64/64 [00:59<00:00,  1.08it/s]\n",
      "2025-01-11 00:26:48,948 - INFO - Dataset test Loaded. Shape: (63941, 7)\n",
      "2025-01-11 00:26:48,950 - INFO - Tokenizing test Dataset\n",
      "Tokenizing test Dataset: 100%|██████████| 64/64 [00:58<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "bge_path = \"/media/wuyuhuan/bge-small-zh\"\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "\n",
    "import logging\n",
    "\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Usable GPU: {torch.cuda.device_count()}\")  \n",
    "tokenizer = AutoTokenizer.from_pretrained(bge_path)\n",
    "\n",
    "def same_seed(seed):\n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def dict2device(data, device):\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, dict):\n",
    "            data[k] = dict2device(v, device)\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            data[k] = v.to(device)\n",
    "    return data\n",
    "\n",
    "same_seed(42)\n",
    "\n",
    "class BGE_FTDataset(Dataset):\n",
    "    def __init__(self, mode: str, in_file: str, tokenizer: AutoTokenizer, ratio: float = 1.0):\n",
    "        \"\"\"\n",
    "        mode: str, one of ['train', 'valid', 'test']\n",
    "        in_file: str, path to the input csv file.\n",
    "        tokenizer: AutoTokenizer, tokenizer for the model.\n",
    "        ratio: float, the ratio of the data to be used. Default: 1.0. \n",
    "            set to 0.01 for functionality testing.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.dataset = pd.read_csv(in_file).sample(frac=ratio)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(bge_path)\n",
    "        logging.info(f\"Dataset {mode} Loaded. Shape: {self.dataset.shape}\")\n",
    "\n",
    "        self.data = []\n",
    "        self.tokenize_data() # -> self.data will look like: [(user_id, job_id, tokenized_cv, tokenized_jd, label), ...] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"user_id\": self.data[idx][0],\n",
    "            \"job_id\": self.data[idx][1],\n",
    "            \"model_input\": {\n",
    "                \"model_input_cv\": self.data[idx][2],\n",
    "                \"model_input_jd\": self.data[idx][3],\n",
    "                \"label\": self.data[idx][4],\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def tokenize_data(self, process_batch_size=1000):\n",
    "        \"\"\"\n",
    "        Tokenize the data in the dataset. The result will be stored in self.data.\n",
    "        \"\"\"\n",
    "        logging.info(f\"Tokenizing {self.mode} Dataset\")\n",
    "        \n",
    "        iter_data = tqdm(\n",
    "            range(0, len(self.dataset), process_batch_size),\n",
    "            total= len(self.dataset) // process_batch_size + 1,\n",
    "            desc=f\"Tokenizing {self.mode} Dataset\"\n",
    "        )\n",
    "        for i in iter_data:\n",
    "            batch = self.dataset.iloc[i:i+process_batch_size]\n",
    "\n",
    "            tokenized_cv = self.tokenizer(batch['cv'].tolist(),padding='max_length',truncation=True,return_tensors='pt') # tokenized_cv: {input_ids: torch.tensor(process_batch_size, d), attention_mask: (process_batch_size, d), token_type_ids: (process_batch_size, d)}\n",
    "\n",
    "            tokenized_jd = self.tokenizer(\n",
    "                batch['jd'].tolist(),padding='max_length',truncation=True,return_tensors='pt') # tokenized_jd: {input_ids: torch.tensor(process_batch_size, d), attention_mask: (process_batch_size, d), token_type_ids: (process_batch_size, d)}\n",
    "            \n",
    "            self.data.extend([(\n",
    "                user_id, \n",
    "                job_id, \n",
    "                {\"input_ids\": tokenized_cv['input_ids'][i], \"attention_mask\": tokenized_cv['attention_mask'][i], \"token_type_ids\": tokenized_cv['token_type_ids'][i]},\n",
    "                {\"input_ids\": tokenized_jd['input_ids'][i], \"attention_mask\": tokenized_jd['attention_mask'][i], \"token_type_ids\": tokenized_jd['token_type_ids'][i]},\n",
    "                torch.tensor(label, dtype=torch.float32)\n",
    "            )\n",
    "            for i, (user_id, job_id, label) in enumerate(\n",
    "                zip(batch['user_id:token'].to_numpy(), \n",
    "                    batch['job_id:token'].to_numpy(), \n",
    "                    batch['browsed:label'].to_numpy()))])\n",
    "\n",
    "train_dataset = BGE_FTDataset('train', 'dataset/processed_train.csv', tokenizer,ratio=1)\n",
    "valid_dataset = BGE_FTDataset('valid', \"dataset/processed_valid.csv\", tokenizer,ratio=1)\n",
    "test_dataset = BGE_FTDataset('test', \"dataset/processed_test.csv\", tokenizer, ratio=1)\n",
    "\n",
    "# train_dataset[0]\n",
    "# valid_dataset[0]\n",
    "# test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, log_loss\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for the BGE-FT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #TODO: the label values are currently only assumed to be binary\n",
    "        # For further experiments, we need to make the label values more general.  \n",
    "        self.uid2topk = {} # {uid: [(score, label), ...]}  \n",
    "        \n",
    "        self.topk = 10\n",
    "        self.metric2func = {\n",
    "            \"ndcg\": self._ndcg,\n",
    "            \"precision\": self._precision,\n",
    "            \"recall\": self._recall,\n",
    "            \"map\": self._map,\n",
    "            \"mrr\": self._mrr,\n",
    "            \"auc\": self._auc,\n",
    "            \"logloss\": self._logloss,\n",
    "        }\n",
    "        self.cls_metrics = [\"auc\", \"logloss\"]\n",
    "        self.rkg_metrics = [\"ndcg\", \"precision\", \"recall\", \"map\", \"mrr\"]\n",
    "    \n",
    "    def collect(self, uid, score, label):\n",
    "        \"\"\"\n",
    "        Process a batch of data. Save the data to the evaluator. \n",
    "        Input params are lists of same length as batch size.\n",
    "        After this func, uid2topk will look like: {uid: [(score, label), ...]}\n",
    "        where each uid has interaction list sorted by score\n",
    "\n",
    "        Args:\n",
    "            uid: list, list of user ids.  \n",
    "            score: list, list of scores.\n",
    "            label: list, list of labels.\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for u, s, l in zip(uid, score, label):\n",
    "            if u not in self.uid2topk:\n",
    "                self.uid2topk[u] = []\n",
    "            self.uid2topk[u].append((s, l)) \n",
    "\n",
    "        for u in self.uid2topk:\n",
    "            self.uid2topk[u] = sorted(self.uid2topk[u], key=lambda x: x[0], reverse=True)\n",
    "         \n",
    "    def evaluate(self, K: List[int]):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the collected data and the pass value k.\n",
    "        Args:\n",
    "            K: List[int], a list of k values for ranking metrics.\n",
    "        \n",
    "        return:\n",
    "            result: dict, a dictionary of evaluation results.\n",
    "            result_str: str, a formatted string of the evaluation results.\n",
    "        \"\"\"\n",
    "        result = {} # {cls_m1: value1, cls_m2: value2, ..., rkg_m1@k1: value1, rkg_m2@k2: value2, ...}\n",
    "\n",
    "        # Calculate the metrics\n",
    "        for cls_metric in self.cls_metrics:\n",
    "            matric_val = self.metric2func[cls_metric]()\n",
    "            result[cls_metric] = matric_val\n",
    "\n",
    "        for rkg_metric in self.rkg_metrics:\n",
    "            for k in K:\n",
    "                result[rkg_metric + '@' + str(k)] = self.metric2func[rkg_metric](k)\n",
    "        \n",
    "        result_str = self._format_str(result)\n",
    "        return result, result_str\n",
    "    \n",
    "    # below are the ranking metric functions. With most of are indirect copy from the recbole.metrics.\n",
    "    def _ndcg(self, k):\n",
    "        base = []\n",
    "        idcg = []\n",
    "\n",
    "        # save base and idcg(Ideal DCG) for each position\n",
    "        for i in range(k):\n",
    "            base.append(np.log(2) / np.log(i + 2)) # np.log(2) / np.log(i + 2) = log_{i + 2}(2)\n",
    "            if i > 0:\n",
    "                idcg.append(base[i] + idcg[i - 1])\n",
    "            else:\n",
    "                idcg.append(base[i])\n",
    "\n",
    "        # calculate the dcg\n",
    "        tot = 0\n",
    "        for uid in self.uid2topk:\n",
    "            dcg = 0\n",
    "            pos = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid][:k]):\n",
    "                dcg += (2 ** label - 1) * base[i] # 2^rel - 1 / log_(2)(i + 1)\n",
    "                pos += label # TODO: If label is not binary, this should be modified.\n",
    "            tot += dcg / idcg[int(pos) - 1]\n",
    "        return tot / len(self.uid2topk)\n",
    "\n",
    "    def _precision(self, k):\n",
    "        tot = 0\n",
    "        valid_length = 0\n",
    "        for uid in self.uid2topk:\n",
    "            rec = 0\n",
    "            rel = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid][:k]):\n",
    "                rec += 1\n",
    "                rel += label # TODO: If label is not binary, this should (maybe) be modified.\n",
    "            try:\n",
    "                tot += rel / rec\n",
    "                valid_length += 1\n",
    "            except:\n",
    "                continue\n",
    "        return tot / valid_length\n",
    "    \n",
    "    def _recall(self, k):\n",
    "        tot = 0\n",
    "        valid_length = 0\n",
    "        for uid in self.uid2topk:\n",
    "            rec = 0\n",
    "            rel = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid]):\n",
    "                if i < k:\n",
    "                    rec += label\n",
    "                rel += label #TODO: If label is not binary, this should (maybe) be modified.\n",
    "            try:\n",
    "                tot += rec / rel\n",
    "                valid_length += 1\n",
    "            except:\n",
    "                continue\n",
    "        return tot / valid_length\n",
    "\n",
    "    # TODO: The MAP and MRR functions are not understood yet.\n",
    "    def _map(self,k):\n",
    "        tot = 0\n",
    "        for uid in self.uid2topk:\n",
    "            tp = 0\n",
    "            pos = 0\n",
    "            ap = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid][:k]):\n",
    "                if label == 1:\n",
    "                    tp += 1\n",
    "                    pos += 1\n",
    "                    ap += tp / (i + 1)\n",
    "            if pos > 0:\n",
    "                tot += ap / pos\n",
    "        return tot / len(self.uid2topk)\n",
    "\n",
    "    def _mrr(self, k):\n",
    "        tot = 0\n",
    "        for uid in self.uid2topk:\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid]):\n",
    "                if label == 1:\n",
    "                    tot += 1 / (i + 1)\n",
    "                    break\n",
    "        return tot / len(self.uid2topk)\n",
    "           \n",
    "    # below are the classification metric functions\n",
    "    def _auc(self):\n",
    "        \"\"\"\n",
    "        Calculate the AUC score.\n",
    "        \"\"\"\n",
    "        total_auc = 0\n",
    "        valid_auc_num = 0\n",
    "        for uid, topk in self.uid2topk.items():\n",
    "            score, labels = zip(*topk)\n",
    "            try:\n",
    "                auc = roc_auc_score(labels, score)\n",
    "                total_auc += auc\n",
    "                valid_auc_num += 1\n",
    "            except:\n",
    "                continue\n",
    "        return total_auc / valid_auc_num\n",
    "        \n",
    "    def _logloss(self):\n",
    "        \"\"\"\n",
    "        Calculate the logloss.\n",
    "        \"\"\"\n",
    "        total_logloss = 0\n",
    "        valid_logloss_num = 0\n",
    "        for uid, topk in self.uid2topk.items():\n",
    "            score, labels = zip(*topk)\n",
    "            try:\n",
    "                logloss = log_loss(labels, score)\n",
    "                valid_logloss_num += 1\n",
    "                total_logloss += logloss\n",
    "            except:\n",
    "                continue\n",
    "        return total_logloss / valid_logloss_num\n",
    "\n",
    "    # other utility functions for evaluator\n",
    "    def _format_str(self, result):\n",
    "        res = ''\n",
    "        for metric in result.keys():\n",
    "            res += '\\n\\t{}:\\t{:.4f}'.format(metric, result[metric])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 00:27:48,151 - INFO - Initializing Model Based on path: /media/wuyuhuan/bge-small-zh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 00:27:51,737 - INFO - Frozing Parameters...\n",
      "2025-01-11 00:27:51,738 - INFO - Model Initialized.\n",
      "2025-01-11 00:27:51,740 - INFO - Trainable Params: 266529. Total Params: 48174369. Trainable Paramaters Ratio: 0.005532589331891405\n",
      "Epoch 0 Train:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA driver initialization failed, you might not have a CUDA gpu.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 299\u001b[0m\n\u001b[1;32m    297\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m    298\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, train_loader, valid_loader, test_loader, optimizer, eval_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 299\u001b[0m best_valid \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m    300\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator()\n\u001b[1;32m    301\u001b[0m result, result_str \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39meval(evaluator)\n",
      "Cell \u001b[0;32mIn[4], line 127\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs, early_stopping_epochs)\u001b[0m\n\u001b[1;32m    123\u001b[0m cur_step_from_best_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(epoch_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader) \u001b[38;5;66;03m# mean loss of this epoch\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# valid\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_epoch(epoch_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_dataloader) \u001b[38;5;66;03m# mean loss of this epoch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 205\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch_idx, train_dataloader)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# 模型前向传播\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# 损失计算\u001b[39;00m\n\u001b[1;32m    207\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcalculate_loss(output, label)\n",
      "File \u001b[0;32m~/anaconda3/envs/recbole/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/recbole/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m, in \u001b[0;36mBGE_FTModel.forward\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     47\u001b[0m step4 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mEvent(enable_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m end \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mEvent(enable_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 50\u001b[0m start\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m     51\u001b[0m jd \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_input_jd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     52\u001b[0m cv \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_input_cv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/anaconda3/envs/recbole/lib/python3.12/site-packages/torch/cuda/streams.py:184\u001b[0m, in \u001b[0;36mEvent.record\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Record the event in a given stream.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03mUses ``torch.cuda.current_stream()`` if no stream is specified. The\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03mstream's device must match the event's device.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     stream \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_stream()\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecord(stream)\n",
      "File \u001b[0;32m~/anaconda3/envs/recbole/lib/python3.12/site-packages/torch/cuda/__init__.py:979\u001b[0m, in \u001b[0;36mcurrent_stream\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_stream\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Stream:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the currently selected :class:`Stream` for a given device.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;124;03m            (default).\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m     _lazy_init()\n\u001b[1;32m    980\u001b[0m     streamdata \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getCurrentStream(\n\u001b[1;32m    981\u001b[0m         _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    982\u001b[0m     )\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Stream(\n\u001b[1;32m    984\u001b[0m         stream_id\u001b[38;5;241m=\u001b[39mstreamdata[\u001b[38;5;241m0\u001b[39m], device_index\u001b[38;5;241m=\u001b[39mstreamdata[\u001b[38;5;241m1\u001b[39m], device_type\u001b[38;5;241m=\u001b[39mstreamdata[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    985\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/recbole/lib/python3.12/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_init()\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA driver initialization failed, you might not have a CUDA gpu."
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=False,num_workers=16, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False,num_workers=16, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False,num_workers=16, pin_memory=True)\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class BGE_FTModel(torch.nn.Module):\n",
    "    def __init__(self, rag_model):\n",
    "        super(BGE_FTModel, self).__init__()\n",
    "        logging.info(f\"Initializing Model Based on path: {rag_model}\")\n",
    "        self.jd_retriever = AutoModel.from_pretrained(rag_model).to(device)\n",
    "        self.cv_retriever = AutoModel.from_pretrained(rag_model).to(device)\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        # xavier initialization for predictor\n",
    "        for m in self.predictor:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "        logging.info(f\"Frozing Parameters...\")\n",
    "        self.frozen_target_parameters()\n",
    "        logging.info(f\"Model Initialized.\")\n",
    "        self.print_trainable_parameters()\n",
    "\n",
    "        self.timing_stats = defaultdict(list)  # For storing timing information\n",
    "\n",
    "    def forward(self, sample):\n",
    "        \"\"\"sample: dict like {\n",
    "            \"model_input_jd\": {\"input_ids\": tensor, \"attention_mask\": tensor, \"token_type_ids\": tensor},\n",
    "            \"model_input_cv\": {\"input_ids\": tensor, \"attention_mask\": tensor, \"token_type_ids\": tensor}\n",
    "            \"label\": tensor\n",
    "        }\n",
    "        \"\"\"\n",
    "        # Create CUDA events for timing\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        step1 = torch.cuda.Event(enable_timing=True)\n",
    "        step2 = torch.cuda.Event(enable_timing=True)\n",
    "        step3 = torch.cuda.Event(enable_timing=True)\n",
    "        step4 = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start.record()\n",
    "        jd = {k: v.squeeze(1) for k, v in sample[\"model_input_jd\"].items()}\n",
    "        cv = {k: v.squeeze(1) for k, v in sample[\"model_input_cv\"].items()}\n",
    "        step1.record()\n",
    "\n",
    "        jd_output = self.jd_retriever(**jd)[0][:, 0]\n",
    "        step2.record() # On avg, 13-14ms, much faster\n",
    "\n",
    "        cv_output = self.cv_retriever(**cv)[0][:, 0] \n",
    "        step3.record() # 592.19 ms -> 593.49 ms ->  595.29 ms -> ... 602.43 ms Why so slow and gradually increasing?\n",
    "\n",
    "        concat_output = torch.cat((jd_output, cv_output), 1)\n",
    "        step4.record()\n",
    "\n",
    "        output = self.predictor(concat_output)\n",
    "        end.record()\n",
    "\n",
    "        # Synchronize CUDA operations\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Record timing statistics\n",
    "        self.timing_stats['data_prep'].append(start.elapsed_time(step1))\n",
    "        self.timing_stats['jd_embedding'].append(step1.elapsed_time(step2)) \n",
    "        self.timing_stats['cv_embedding'].append(step2.elapsed_time(step3)) \n",
    "        self.timing_stats['concatenation'].append(step3.elapsed_time(step4))\n",
    "        self.timing_stats['prediction'].append(step4.elapsed_time(end))\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def calculate_loss(self, output, label):\n",
    "        #TODO: Apply more innovative loss functions.\n",
    "        return self.loss_fn(output, label)\n",
    "\n",
    "    def frozen_target_parameters(self):\n",
    "        for param in self.jd_retriever.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.cv_retriever.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def print_trainable_parameters(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        logging.info(f\"Trainable Params: {trainable_params}. Total Params: {total_params}. Trainable Paramaters Ratio: {trainable_params/total_params}\")\n",
    "\n",
    "    def get_average_timings(self):\n",
    "        \"\"\"Get average timing statistics\"\"\"\n",
    "        return {\n",
    "            step: sum(times)/len(times) if times else 0 \n",
    "            for step, times in self.timing_stats.items()\n",
    "        }\n",
    "\n",
    "    def reset_timings(self):\n",
    "        \"\"\"Reset timing statistics\"\"\"\n",
    "        self.timing_stats.clear()\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, train_dataloader, valid_dataloader, test_dataloader, optimizer, eval_step, verbose=True):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.clip_grad_norm = None\n",
    "        self.optimizer = optimizer\n",
    "        self.eval_step = 1\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def train(self, epochs, early_stopping_epochs=5):\n",
    "        train_loss = valid_loss = float('inf')\n",
    "        \n",
    "        # the below init values are for early stopping\n",
    "        best_valid = cur_best_valid = float('inf')\n",
    "        cur_step_from_best_val = 0\n",
    "        \n",
    "        for epoch_idx in range(epochs):\n",
    "            # train\n",
    "            train_loss = self._train_epoch(epoch_idx, self.train_dataloader) # mean loss of this epoch\n",
    "\n",
    "            # valid\n",
    "            valid_loss = self._valid_epoch(epoch_idx, self.valid_dataloader) # mean loss of this epoch\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Epoch {epoch_idx} Train mean Loss: {train_loss:.4f}, Valid mean Loss: {valid_loss:.4f}\")\n",
    "                \n",
    "            # early stopping\n",
    "            if (epoch_idx + 1) % self.eval_step == 0:\n",
    "                if self.verbose:\n",
    "                    logging.info(f\"Epoch {epoch_idx + 1} starts early stopping check.\")\n",
    "                cur_best_valid, cur_step_from_best_val, stop_flag, update_flag = self._early_stopping(\n",
    "                    valid_loss, cur_best_valid, cur_step_from_best_val, early_stopping_epochs, lower_is_better=True) # -> best, cur_step, stop_flag, update_flag\n",
    "                \n",
    "                if update_flag:\n",
    "                    best_valid = cur_best_valid\n",
    "            \n",
    "                if stop_flag:\n",
    "                    if self.verbose:\n",
    "                        logging.info(f\"Early stopping at epoch {epoch_idx}\")\n",
    "                    break\n",
    "        \n",
    "        return best_valid\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval(self, evaluator):\n",
    "        \"\"\"\n",
    "        Using the test dataloader to evaluate the model.\n",
    "        For each (cv, jd) pair, we predict the probability of the cv being browsed.\n",
    "        The evaluation results are saved to the save_path as the following format:\n",
    "\n",
    "        The evaluation matriceare all based on top-k selection. for each cv_i, the \n",
    "        top-k are selected from all (cv_i, jd) pairs that appear in the test set. \n",
    "        After consideration, due to the context of precise-recommendation matching \n",
    "        task, we decide if jd_j are in the testset records but not being recorded \n",
    "        with cv_i in the testset, we will not consider jd_j in the top-k selection\n",
    "        for cv_i.\n",
    "        \n",
    "        params:\n",
    "            evaluator: Evaluator, the evaluator for the model.\n",
    "\n",
    "        return:\n",
    "            result: list\n",
    "        \"\"\"\n",
    "        # set model to eval mode\n",
    "        if self.verbose:\n",
    "            logging.info(\"Start evaluating on test set\")\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "        pbar = tqdm(enumerate(self.test_dataloader), total=len(self.test_dataloader), desc=\"Matrices Evaluation     \")\n",
    "       \n",
    "        # predicting scores, while saving the predictions records.\n",
    "        for step, batch in pbar:\n",
    "            uid = batch[\"user_id\"] # List of length bs\n",
    "            batch_inputs = dict2device(batch[\"model_input\"], device) # {\"model_input_jd\": dict, \"model_input_cv\": dict, \"label\": tensor}\n",
    "            scores = self.model(batch_inputs).squeeze(-1).cpu().tolist()\n",
    "            labels = batch_inputs[\"label\"].squeeze(-1).cpu().tolist()\n",
    "            evaluator.collect(uid, scores, labels)\n",
    "\n",
    "        # evaluate the results\n",
    "        results, results_str = evaluator.evaluate([1, 5, 10])\n",
    "        return results, results_str\n",
    "\n",
    "    # below is indirect copy from https://github.com/hyp1231/SHPJF/tree/master/model\n",
    "    def _train_epoch(self, epoch_idx: int, train_dataloader: DataLoader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_batches = len(train_dataloader)\n",
    "        \n",
    "        pbar = tqdm(enumerate(train_dataloader), total=total_batches, desc=f\"Epoch {epoch_idx} Train\")\n",
    "\n",
    "        for step, batch in pbar:\n",
    "            batch = dict2device(batch[\"model_input\"], device)\n",
    "            label = batch[\"label\"].unsqueeze(1).to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # 模型前向传播\n",
    "            output = self.model(batch)\n",
    "            # 损失计算\n",
    "            loss = self.model.calculate_loss(output, label)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            \n",
    "            # 梯度裁剪（如果启用）\n",
    "            if self.clip_grad_norm:\n",
    "                clip_grad_norm_(self.model.parameters(), **self.clip_grad_norm)\n",
    "            \n",
    "            # 优化器步骤\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # 更新进度条显示\n",
    "            pbar.set_postfix_str(f\"loss: {loss.item():.4f}\")\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            self._check_nan(loss)\n",
    "\n",
    "            if (step + 1) % 10 == 0:\n",
    "                avg_times = model.get_average_timings()\n",
    "                for step, avg_time in avg_times.items():\n",
    "                    print(f\"{step}: {avg_time:.2f} ms\")\n",
    "            \n",
    "            \n",
    "        return total_loss / total_batches\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _valid_epoch(self, epoch_idx: int, valid_dataloader: DataLoader):\n",
    "        \"\"\"valid the model with valid data by calculate the loss\n",
    "        \"\"\"\n",
    "        \n",
    "        # set model to eval mode\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_batches = len(valid_dataloader)\n",
    "        pbar = tqdm(enumerate(valid_dataloader), total=total_batches, desc=f\"Epoch {epoch_idx} Valid\")\n",
    "\n",
    "        # calculate loss on validation set\n",
    "        for step, batch in pbar:\n",
    "            batch = dict2device(batch[\"model_input\"], device) # batch: {\"model_input_jd\": dict, \"model_input_cv\": dict, \"label\": tensor}\n",
    "            label = batch[\"label\"].unsqueeze(1) # (bs, 1)\n",
    "            output = self.model(batch) # (bs, 1)\n",
    "            loss = self.model.calculate_loss(output, label) # output: (bs, 1), label: (bs, 1)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            total_loss += loss.item()\n",
    "            self._check_nan(loss)\n",
    "\n",
    "        return total_loss / total_batches\n",
    "    \n",
    "    def _early_stopping(self, value, best, cur_step, max_step, lower_is_better=True):\n",
    "        \"\"\"validation-based early stopping\n",
    "\n",
    "        Args:\n",
    "            value (float): current result\n",
    "            best (float): best result\n",
    "            cur_step (int): the number of consecutive steps that did not exceed the best result\n",
    "            max_step (int): threshold steps for stopping\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "            - best: float,\n",
    "            best result after this step\n",
    "            - cur_step: int,\n",
    "            the number of consecutive steps that did not exceed the best result after this step\n",
    "            - stop_flag: bool,\n",
    "            whether to stop\n",
    "            - update_flag: bool,\n",
    "            whether to update\n",
    "        \"\"\"\n",
    "        stop_flag = False\n",
    "        update_flag = False\n",
    "\n",
    "        better = value < best if lower_is_better else value > best\n",
    "        if better:\n",
    "            cur_step = 0\n",
    "            best = value\n",
    "            update_flag = True\n",
    "        else:\n",
    "            cur_step += 1\n",
    "            if cur_step > max_step:\n",
    "                stop_flag = True\n",
    "        return best, cur_step, stop_flag, update_flag\n",
    "\n",
    "    def _check_nan(self, loss):\n",
    "        if torch.isnan(loss).any():\n",
    "            raise ValueError(\"Model diverged with loss = NaN\")\n",
    "        return\n",
    "\n",
    "    \n",
    "model = BGE_FTModel(bge_path).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.BCELoss()\n",
    "trainer = Trainer(model, train_loader, valid_loader, test_loader, optimizer, eval_step=1)\n",
    "best_valid = trainer.train(epochs = 1000)\n",
    "evaluator = Evaluator()\n",
    "result, result_str = trainer.eval(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BGE_FTDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m BGE_FTDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/processed_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer,ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m BGE_FTDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/processed_valid.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer,ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m BGE_FTDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/processed_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BGE_FTDataset' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dataset = BGE_FTDataset('train', 'dataset/processed_train.csv', tokenizer,ratio=1)\n",
    "valid_dataset = BGE_FTDataset('valid', \"dataset/processed_valid.csv\", tokenizer,ratio=1)\n",
    "test_dataset = BGE_FTDataset('test', \"dataset/processed_test.csv\", tokenizer, ratio=1)\n",
    "\n",
    "def save_tokenized_dataset_to_json(dataset, output_file):\n",
    "    \"\"\"\n",
    "    将 IterableDataset 的 tokenized 文本逐条存储到 JSON 文件中。\n",
    "\n",
    "    Args:\n",
    "        dataset (IterableDataset): 实现了 __iter__ 方法的 dataset，如 BGE_FTDataset。\n",
    "        output_file (str): 要保存的 JSON 文件路径。\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in tqdm(dataset, desc=\"Saving tokenized dataset to JSON\"):\n",
    "            # 将 PyTorch 张量转换为可序列化的格式\n",
    "            serialized_sample = {\n",
    "                \"user_id\": sample[\"user_id\"],  # 字符串或基本数据类型，直接存储\n",
    "                \"job_id\": sample[\"job_id\"],    # 字符串或基本数据类型，直接存储\n",
    "                \"model_input\": {\n",
    "                    \"model_input_cv\": {\n",
    "                        k: v.tolist() for k, v in sample[\"model_input\"][\"model_input_cv\"].items()\n",
    "                    },\n",
    "                    \"model_input_jd\": {\n",
    "                        k: v.tolist() for k, v in sample[\"model_input\"][\"model_input_jd\"].items()\n",
    "                    },\n",
    "                    \"label\": sample[\"model_input\"][\"label\"].item()  # 转为 float\n",
    "                }\n",
    "            }\n",
    "            # 将该样本写入 JSON 文件，每行一个样本\n",
    "            f.write(json.dumps(serialized_sample) + '\\n')\n",
    "\n",
    "train_dataset = BGE_FTDataset('train', 'dataset/processed_train.csv', tokenizer,ratio=1)\n",
    "valid_dataset = BGE_FTDataset('valid', \"dataset/processed_valid.csv\", tokenizer,ratio=1)\n",
    "test_dataset = BGE_FTDataset('test', \"dataset/processed_test.csv\", tokenizer, ratio=1)\n",
    "\n",
    "save_tokenized_dataset_to_json(train_dataset, '/media/wuyuhuan/tokenids/train_token_jsons.json')\n",
    "save_tokenized_dataset_to_json(valid_dataset, '/media/wuyuhuan/tokenids/valid_token_jsons.json')\n",
    "save_tokenized_dataset_to_json(test_dataset, '/media/wuyuhuan/tokenids/test_token_jsons.json')\n",
    "# 示例用法\n",
    "# 假设你已经定义了 BGE_FTDataset\n",
    "# dataset = BGE_FTDataset(mode='train', in_file='path/to/input.csv', tokenizer=your_tokenizer)\n",
    "# save_tokenized_dataset_to_json(dataset, output_file='output.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'auc': 0.49484767025089593,\n",
    " 'logloss': 0.8752708701473016,\n",
    " 'ndcg@1': 0.20637408568443052,\n",
    " 'precision@1': 0.20637408568443052,\n",
    " 'recall@1': 0.6475362318840581,\n",
    " 'map@1': 0.20637408568443052,\n",
    " 'mrr@1': 0.24705304274269782}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5313714494507185,\n",
       " 'logloss': 0.5764790056676369,\n",
       " 'ndcg@1': 0.2520190023752969,\n",
       " 'ndcg@5': 0.4664345684607033,\n",
       " 'ndcg@10': 0.5028075114044772,\n",
       " 'precision@1': 0.2520190023752969,\n",
       " 'precision@5': 0.24563737133808594,\n",
       " 'precision@10': 0.2415688270557644,\n",
       " 'recall@1': 0.13997698901130962,\n",
       " 'recall@5': 0.4863068289489413,\n",
       " 'recall@10': 0.7198235059496314,\n",
       " 'map@1': 0.2520190023752969,\n",
       " 'map@5': 0.38942564001055857,\n",
       " 'map@10': 0.38262279548927025,\n",
       " 'mrr@1': 0.4238476160112081,\n",
       " 'mrr@5': 0.4238476160112081,\n",
       " 'mrr@10': 0.4238476160112081}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
