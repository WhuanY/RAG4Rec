{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".inter\n",
    "(g, j, s)\n",
    "g.info <- .udoc\n",
    "j.info <- .idoc\n",
    "\n",
    "g.strRep -> C \n",
    "            o          M\n",
    "            n --BGE--> L ---> out\n",
    "            c --BGE--> P ---> put\n",
    "            a          s\n",
    "j.strRep -> t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:31:09) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 16:55:39,119 - INFO - Using BGE model from /media/wuyuhuan/bge-small-zh\n",
      "2025-01-21 16:55:39,121 - INFO - Torch Imported. Using PyTorch version 2.5.1\n",
      "2025-01-21 16:55:39,123 - INFO - Usable GPU: 9, device using: cuda:1\n",
      "2025-01-21 16:55:39,247 - INFO - Setting all seeds to 42 to ensure reproducibility...\n",
      "2025-01-21 16:55:46,166 - INFO - Dataset train Loaded. Shape: (3929, 7)\n",
      "2025-01-21 16:55:47,299 - INFO - Dataset valid Loaded. Shape: (614, 7)\n",
      "2025-01-21 16:55:48,435 - INFO - Dataset test Loaded. Shape: (614, 7)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "bge_path = \"/media/wuyuhuan/bge-small-zh\"\n",
    "logging.info(f\"Using BGE model from {bge_path}\")\n",
    "import torch\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "logging.info(f\"Torch Imported. Using PyTorch version {torch.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from peft import LoraModel, LoraConfig\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Usable GPU: {torch.cuda.device_count()}, device using: {device}\")  \n",
    "tokenizer = AutoTokenizer.from_pretrained(bge_path)\n",
    "\n",
    "def same_seed(seed):\n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    logging.info(f\"Setting all seeds to {seed} to ensure reproducibility...\")\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def dict2device(data, device):\n",
    "    for k, v in data.items():\n",
    "        if isinstance(v, dict):\n",
    "            data[k] = dict2device(v, device)\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            data[k] = v.to(device)\n",
    "    return data\n",
    "\n",
    "same_seed(42)\n",
    "\n",
    "class BGE_FTDataset(Dataset):\n",
    "    def __init__(self, mode: str, in_file: str, tokenizer: AutoTokenizer, ratio: float = 1.0):\n",
    "        \"\"\"\n",
    "        mode: str, one of ['train', 'valid', 'test']\n",
    "        in_file: str, path to the input csv file.\n",
    "        tokenizer: AutoTokenizer, tokenizer for the model.\n",
    "        ratio: float, the ratio of the data to be used. Default: 1.0. \n",
    "            set to 0.01 for functionality testing.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.dataset = pd.read_csv(in_file).sample(frac=ratio)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(bge_path)\n",
    "        logging.info(f\"Dataset {mode} Loaded. Shape: {self.dataset.shape}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx]\n",
    "        return {\n",
    "            \"user_id\": row['user_id:token'],\n",
    "            \"job_id\": row['job_id:token'],\n",
    "            \"text_pair\": (row[\"cv\"], row[\"jd\"]),\n",
    "            \"label\": row[\"browsed:label\"]}\n",
    "\n",
    "train_dataset = BGE_FTDataset('train', 'dataset/processed_train.csv', tokenizer,ratio=0.01)\n",
    "valid_dataset = BGE_FTDataset('valid', \"dataset/processed_valid.csv\", tokenizer,ratio=0.01)\n",
    "test_dataset = BGE_FTDataset('test', \"dataset/processed_test.csv\", tokenizer, ratio=0.01)\n",
    "\n",
    "# train_dataset[0]\n",
    "# valid_dataset[0]\n",
    "# test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, tokenizer):\n",
    "    user_ids = [item['user_id'] for item in batch]\n",
    "    job_ids = [item['job_id'] for item in batch]\n",
    "    cv_texts, jd_texts = zip(*[item['text_pair'] for item in batch])\n",
    "    labels = [item['label'] for item in batch]\n",
    "\n",
    "    tokenized_cv = tokenizer(text=cv_texts, \n",
    "                             text_pair=jd_texts,\n",
    "                             padding='max_length',\n",
    "                             truncation=True,\n",
    "                             return_tensors='pt')\n",
    "\n",
    "    return {\n",
    "        'user_id':user_ids,\n",
    "        'job_id':job_ids,\n",
    "        'model_input': {\n",
    "            'input_ids': tokenized_cv['input_ids'],\n",
    "            'attention_mask': tokenized_cv['attention_mask'],\n",
    "            'token_type_ids': tokenized_cv['token_type_ids']\n",
    "            }, \n",
    "        'label': torch.tensor(labels, dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "# Create dataloaders with parallel processing\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: collate_fn(x, tokenizer),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: collate_fn(x, tokenizer),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: collate_fn(x, tokenizer),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, log_loss\n",
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    Evaluator for the BGE-FT model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #TODO: the label values are currently only assumed to be binary\n",
    "        # For further experiments, we need to make the label values more general.  \n",
    "        self.uid2topk = {} # {uid: [(score, label), ...]}  \n",
    "        \n",
    "        self.topk = 10\n",
    "        self.metric2func = {\n",
    "            \"ndcg\": self._ndcg,\n",
    "            \"precision\": self._precision,\n",
    "            \"recall\": self._recall,\n",
    "            \"map\": self._map,\n",
    "            \"mrr\": self._mrr,\n",
    "            \"auc\": self._auc,\n",
    "            \"logloss\": self._logloss,\n",
    "        }\n",
    "        self.cls_metrics = [\"auc\", \"logloss\"]\n",
    "        self.rkg_metrics = [\"ndcg\", \"precision\", \"recall\", \"map\", \"mrr\"]\n",
    "    \n",
    "    def collect(self, uid, score, label):\n",
    "        \"\"\"\n",
    "        Process a batch of data. Save the data to the evaluator. \n",
    "        Input params are lists of same length as batch size.\n",
    "        After this func, uid2topk will look like: {uid: [(score, label), ...]}\n",
    "        where each uid has interaction list sorted by score\n",
    "\n",
    "        Args:\n",
    "            uid: list, list of user ids.  \n",
    "            score: list, list of scores.\n",
    "            label: list, list of labels.\n",
    "            \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for u, s, l in zip(uid, score, label):\n",
    "            if u not in self.uid2topk:\n",
    "                self.uid2topk[u] = []\n",
    "            self.uid2topk[u].append((s, l)) \n",
    "\n",
    "        for u in self.uid2topk:\n",
    "            self.uid2topk[u] = sorted(self.uid2topk[u], key=lambda x: x[0], reverse=True)\n",
    "         \n",
    "    def evaluate(self, K: List[int]):\n",
    "        \"\"\"\n",
    "        Evaluate the model using the collected data and the pass value k.\n",
    "        Args:\n",
    "            K: List[int], a list of k values for ranking metrics.\n",
    "        \n",
    "        return:\n",
    "            result: dict, a dictionary of evaluation results.\n",
    "            result_str: str, a formatted string of the evaluation results.\n",
    "        \"\"\"\n",
    "        result = {} # {cls_m1: value1, cls_m2: value2, ..., rkg_m1@k1: value1, rkg_m2@k2: value2, ...}\n",
    "\n",
    "        # Calculate the metrics\n",
    "        for cls_metric in self.cls_metrics:\n",
    "            matric_val = self.metric2func[cls_metric]()\n",
    "            result[cls_metric] = matric_val\n",
    "\n",
    "        for rkg_metric in self.rkg_metrics:\n",
    "            for k in K:\n",
    "                result[rkg_metric + '@' + str(k)] = self.metric2func[rkg_metric](k)\n",
    "        \n",
    "        result_str = self._format_str(result)\n",
    "        return result, result_str\n",
    "    \n",
    "    # below are the ranking metric functions. With most of are indirect copy from the recbole.metrics.\n",
    "    def _ndcg(self, k):\n",
    "        base = []\n",
    "        idcg = []\n",
    "\n",
    "        # save base and idcg(Ideal DCG) for each position\n",
    "        for i in range(k):\n",
    "            base.append(np.log(2) / np.log(i + 2)) # np.log(2) / np.log(i + 2) = log_{i + 2}(2)\n",
    "            if i > 0:\n",
    "                idcg.append(base[i] + idcg[i - 1])\n",
    "            else:\n",
    "                idcg.append(base[i])\n",
    "\n",
    "        # calculate the dcg\n",
    "        tot = 0\n",
    "        for uid in self.uid2topk:\n",
    "            dcg = 0\n",
    "            pos = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid][:k]):\n",
    "                dcg += (2 ** label - 1) * base[i] # 2^rel - 1 / log_(2)(i + 1)\n",
    "                pos += label # TODO: If label is not binary, this should be modified.\n",
    "            tot += dcg / idcg[int(pos) - 1]\n",
    "        return tot / len(self.uid2topk)\n",
    "\n",
    "    def _precision(self, k):\n",
    "        tot = 0\n",
    "        valid_length = 0\n",
    "        for uid in self.uid2topk:\n",
    "            rec = 0\n",
    "            rel = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid][:k]):\n",
    "                rec += 1\n",
    "                rel += label # TODO: If label is not binary, this should (maybe) be modified.\n",
    "            try:\n",
    "                tot += rel / rec\n",
    "                valid_length += 1\n",
    "            except:\n",
    "                continue\n",
    "        return tot / valid_length\n",
    "    \n",
    "    def _recall(self, k):\n",
    "        tot = 0\n",
    "        valid_length = 0\n",
    "        for uid in self.uid2topk:\n",
    "            rec = 0\n",
    "            rel = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid]):\n",
    "                if i < k:\n",
    "                    rec += label\n",
    "                rel += label #TODO: If label is not binary, this should (maybe) be modified.\n",
    "            try:\n",
    "                tot += rec / rel\n",
    "                valid_length += 1\n",
    "            except:\n",
    "                continue\n",
    "        return tot / valid_length\n",
    "\n",
    "    # TODO: The MAP and MRR functions are not understood yet.\n",
    "    def _map(self,k):\n",
    "        tot = 0\n",
    "        for uid in self.uid2topk:\n",
    "            tp = 0\n",
    "            pos = 0\n",
    "            ap = 0\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid][:k]):\n",
    "                if label == 1:\n",
    "                    tp += 1\n",
    "                    pos += 1\n",
    "                    ap += tp / (i + 1)\n",
    "            if pos > 0:\n",
    "                tot += ap / pos\n",
    "        return tot / len(self.uid2topk)\n",
    "\n",
    "    def _mrr(self, k):\n",
    "        tot = 0\n",
    "        for uid in self.uid2topk:\n",
    "            for i, (score, label) in enumerate(self.uid2topk[uid]):\n",
    "                if label == 1:\n",
    "                    tot += 1 / (i + 1)\n",
    "                    break\n",
    "        return tot / len(self.uid2topk)\n",
    "           \n",
    "    # below are the classification metric functions\n",
    "    def _auc(self):\n",
    "        \"\"\"\n",
    "        Calculate the AUC score.\n",
    "        \"\"\"\n",
    "        total_auc = 0\n",
    "        valid_auc_num = 0\n",
    "        for uid, topk in self.uid2topk.items():\n",
    "            score, labels = zip(*topk)\n",
    "            try:\n",
    "                auc = roc_auc_score(labels, score)\n",
    "                total_auc += auc\n",
    "                valid_auc_num += 1\n",
    "            except:\n",
    "                continue\n",
    "        return total_auc / valid_auc_num\n",
    "        \n",
    "    def _logloss(self):\n",
    "        \"\"\"\n",
    "        Calculate the logloss.\n",
    "        \"\"\"\n",
    "        total_logloss = 0\n",
    "        valid_logloss_num = 0\n",
    "        for uid, topk in self.uid2topk.items():\n",
    "            score, labels = zip(*topk)\n",
    "            try:\n",
    "                logloss = log_loss(labels, score)\n",
    "                valid_logloss_num += 1\n",
    "                total_logloss += logloss\n",
    "            except:\n",
    "                continue\n",
    "        return total_logloss / valid_logloss_num\n",
    "\n",
    "    # other utility functions for evaluator\n",
    "    def _format_str(self, result):\n",
    "        res = ''\n",
    "        for metric in result.keys():\n",
    "            res += '\\n\\t{}:\\t{:.4f}'.format(metric, result[metric])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class BGE_FTModel(torch.nn.Module):\n",
    "    def __init__(self, rag_model):\n",
    "        super(BGE_FTModel, self).__init__()\n",
    "        logging.info(f\"Initializing Model Based on path: {rag_model}\")\n",
    "        self.text_matcher = AutoModel.from_pretrained(rag_model).to(device)\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "        ).to(device)\n",
    "\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        # xavier initialization for predictor\n",
    "        for m in self.predictor:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "        config = LoraConfig(r=4, lora_alpha=4, target_modules=[\"query\", \"key\"])\n",
    "        self.text_matcher = LoraModel(self.text_matcher, config, adapter_name=\"default\").to(device)\n",
    "        \n",
    "        # logging.info(f\"Frozing Parameters...\")\n",
    "        # self.frozen_target_parameters()\n",
    "        # logging.info(f\"Model Initialized.\")\n",
    "        self.print_trainable_parameters()\n",
    "\n",
    "        self.timing_stats = defaultdict(list)  # For storing timing information\n",
    "\n",
    "    def forward(self, sample):\n",
    "        \"\"\"sample: dict like {\n",
    "            \"user_id\": list,\n",
    "            \"job_id\": list,\n",
    "            \"model_input\": {\"input_ids\": tensor, \"attention_mask\": tensor, \"token_type_ids\": tensor},\n",
    "            \"label\": tensor\n",
    "        }\n",
    "        \"\"\"\n",
    "        # Create CUDA events for timing\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        step1 = torch.cuda.Event(enable_timing=True)\n",
    "        step2 = torch.cuda.Event(enable_timing=True)\n",
    "        step3 = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start.record()\n",
    "        text_input = {k: v.squeeze(1) for k, v in sample[\"model_input\"].items()}\n",
    "        step1.record()\n",
    "        text_output = self.text_matcher(**text_input)[0][:, 0] \n",
    "        step2.record()\n",
    "        output = self.predictor(text_output)\n",
    "        step3.record()\n",
    "        end.record()\n",
    "\n",
    "        # Synchronize CUDA operations\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Record timing statistics\n",
    "        self.timing_stats['data_prep'].append(start.elapsed_time(step1))\n",
    "        self.timing_stats['text_matcher'].append(step1.elapsed_time(step2))\n",
    "        self.timing_stats['predictor'].append(step2.elapsed_time(step3))\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def calculate_loss(self, output, label):\n",
    "        #TODO: Apply more innovative loss functions.\n",
    "        return self.loss_fn(output, label)\n",
    "\n",
    "    def frozen_target_parameters(self):\n",
    "        logging.info(f\"Frozing Parameters...\")\n",
    "        for param in self.text_matcher.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.print_trainable_parameters()\n",
    "    \n",
    "    def print_trainable_parameters(self):\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        logging.info(f\"Trainable Params: {trainable_params}. Total Params: {total_params}. Trainable Paramaters Ratio: {trainable_params/total_params}\")\n",
    "\n",
    "    def get_average_timings(self):\n",
    "        \"\"\"Get average timing statistics\"\"\"\n",
    "        return {\n",
    "            step: sum(times)/len(times) if times else 0 \n",
    "            for step, times in self.timing_stats.items()\n",
    "        }\n",
    "\n",
    "    def reset_timings(self):\n",
    "        \"\"\"Reset timing statistics\"\"\"\n",
    "        self.timing_stats.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, train_dataloader, valid_dataloader, test_dataloader, optimizer, eval_step, verbose=True):\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.clip_grad_norm = None\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scaler = GradScaler() # for mixed precision training \n",
    "        self.eval_step = 1\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def train(self, epochs, early_stopping_epochs=5):\n",
    "        train_loss = valid_loss = float('inf')\n",
    "        \n",
    "        # the below init values are for early stopping\n",
    "        best_valid = cur_best_valid = float('inf')\n",
    "        cur_step_from_best_val = 0\n",
    "        \n",
    "        for epoch_idx in range(epochs):\n",
    "            # train\n",
    "            train_loss = self._train_epoch(epoch_idx, self.train_dataloader) # mean loss of this epoch\n",
    "\n",
    "            # valid\n",
    "            valid_loss = self._valid_epoch(epoch_idx, self.valid_dataloader) # mean loss of this epoch\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Epoch {epoch_idx} Train mean Loss: {train_loss:.4f}, Valid mean Loss: {valid_loss:.4f}\")\n",
    "                \n",
    "            # early stopping\n",
    "            if (epoch_idx + 1) % self.eval_step == 0:\n",
    "                if self.verbose:\n",
    "                    logging.info(f\"Epoch {epoch_idx + 1} starts early stopping check.\")\n",
    "                cur_best_valid, cur_step_from_best_val, stop_flag, update_flag = self._early_stopping(\n",
    "                    valid_loss, cur_best_valid, cur_step_from_best_val, early_stopping_epochs, lower_is_better=True) # -> best, cur_step, stop_flag, update_flag\n",
    "                \n",
    "                if update_flag:\n",
    "                    best_valid = cur_best_valid\n",
    "            \n",
    "                if stop_flag:\n",
    "                    if self.verbose:\n",
    "                        logging.info(f\"Early stopping at epoch {epoch_idx}\")\n",
    "                    break\n",
    "        \n",
    "        return best_valid\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval(self, evaluator):\n",
    "        \"\"\"\n",
    "        Using the test dataloader to evaluate the model.\n",
    "        For each (cv, jd) pair, we predict the probability of the cv being browsed.\n",
    "        The evaluation results are saved to the save_path as the following format:\n",
    "\n",
    "        The evaluation matriceare all based on top-k selection. for each cv_i, the \n",
    "        top-k are selected from all (cv_i, jd) pairs that appear in the test set. \n",
    "        After consideration, due to the context of precise-recommendation matching \n",
    "        task, we decide if jd_j are in the testset records but not being recorded \n",
    "        with cv_i in the testset, we will not consider jd_j in the top-k selection\n",
    "        for cv_i.\n",
    "        \n",
    "        params:\n",
    "            evaluator: Evaluator, the evaluator for the model.\n",
    "\n",
    "        return:\n",
    "            result: list\n",
    "        \"\"\"\n",
    "        # set model to eval mode\n",
    "        if self.verbose:\n",
    "            logging.info(\"Start evaluating on test set\")\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "        pbar = tqdm(enumerate(self.test_dataloader), total=len(self.test_dataloader), desc=\"Matrices Evaluation     \")\n",
    "       \n",
    "        # predicting scores, while saving the predictions records.\n",
    "        for step, sample in pbar:\n",
    "            uid = sample[\"user_id\"] # List of length bs\n",
    "            sample = dict2device(sample, device) # {\"model_input_jd\": dict, \"model_input_cv\": dict, \"label\": tensor}\n",
    "            scores = self.model(sample).squeeze(-1).cpu().tolist()\n",
    "            labels = sample[\"label\"].squeeze(-1).cpu().tolist()\n",
    "            evaluator.collect(uid, scores, labels)\n",
    "\n",
    "        # evaluate the results\n",
    "        results, results_str = evaluator.evaluate([1, 5, 10])\n",
    "        return results, results_str\n",
    "\n",
    "    # below is indirect copy from https://github.com/hyp1231/SHPJF/tree/master/model\n",
    "    def _train_epoch(self, epoch_idx: int, train_dataloader: DataLoader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_batches = len(train_dataloader)\n",
    "        \n",
    "        pbar = tqdm(enumerate(train_dataloader), total=total_batches, desc=f\"Epoch {epoch_idx} Train\")\n",
    "\n",
    "        for step, sample in pbar:\n",
    "            # Create new events for each iteration\n",
    "            start = torch.cuda.Event(enable_timing=True)\n",
    "            forward_end = torch.cuda.Event(enable_timing=True)\n",
    "            loss_end = torch.cuda.Event(enable_timing=True)\n",
    "            backward_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "            start.record()\n",
    "            sample = dict2device(sample, device)\n",
    "            label = sample[\"label\"].unsqueeze(1).to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # 模型前向传播\n",
    "            with autocast(device_type=str(device),dtype=torch.float16):\n",
    "                output = self.model(sample)\n",
    "                forward_end.record()\n",
    "                # 损失计算\n",
    "                loss = self.model.calculate_loss(output, label)\n",
    "                loss_end.record()\n",
    "            # Use scaler for backward pass\n",
    "            self.scaler.scale(loss).backward() \n",
    "            backward_end.record()\n",
    "            \n",
    "            # 梯度裁剪（如果启用）\n",
    "            if self.clip_grad_norm:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                clip_grad_norm_(self.model.parameters(), **self.clip_grad_norm)\n",
    "            \n",
    "            # 优化器步骤\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            # 更新进度条显示\n",
    "            forward_elapsed_time = start.elapsed_time(forward_end)\n",
    "            loss_elapsed_time = forward_end.elapsed_time(loss_end)\n",
    "            backward_elapsed_time = loss_end.elapsed_time(backward_end)\n",
    "            pbar.set_postfix_str(f\"loss: {loss.item():.4f} | forward: {forward_elapsed_time:.2f} ms | loss: {loss_elapsed_time:.2f} ms | backward: {backward_elapsed_time:.2f} ms\")\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            self._check_nan(loss)\n",
    "            \n",
    "        return total_loss / total_batches\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _valid_epoch(self, epoch_idx: int, valid_dataloader: DataLoader):\n",
    "        \"\"\"valid the model with valid data by calculate the loss\n",
    "        \"\"\"\n",
    "        \n",
    "        # set model to eval mode\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_batches = len(valid_dataloader)\n",
    "        pbar = tqdm(enumerate(valid_dataloader), total=total_batches, desc=f\"Epoch {epoch_idx} Valid\")\n",
    "\n",
    "        # calculate loss on validation set\n",
    "        for step, sample in pbar:\n",
    "            sample = dict2device(sample, device) # batch: {\"model_input_jd\": dict, \"model_input_cv\": dict, \"label\": tensor}\n",
    "            label = sample[\"label\"].unsqueeze(1) # (bs, 1)\n",
    "            output = self.model(sample) # (bs, 1)\n",
    "            loss = self.model.calculate_loss(output, label) # output: (bs, 1), label: (bs, 1)\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            total_loss += loss.item()\n",
    "            self._check_nan(loss)\n",
    "\n",
    "        return total_loss / total_batches\n",
    "    \n",
    "    def _early_stopping(self, value, best, cur_step, max_step, lower_is_better=True):\n",
    "        \"\"\"validation-based early stopping\n",
    "\n",
    "        Args:\n",
    "            value (float): current result\n",
    "            best (float): best result\n",
    "            cur_step (int): the number of consecutive steps that did not exceed the best result\n",
    "            max_step (int): threshold steps for stopping\n",
    "\n",
    "        Returns:\n",
    "            tuple:\n",
    "            - best: float,\n",
    "            best result after this step\n",
    "            - cur_step: int,\n",
    "            the number of consecutive steps that did not exceed the best result after this step\n",
    "            - stop_flag: bool,\n",
    "            whether to stop\n",
    "            - update_flag: bool,\n",
    "            whether to update\n",
    "        \"\"\"\n",
    "        stop_flag = False\n",
    "        update_flag = False\n",
    "\n",
    "        better = value < best if lower_is_better else value > best\n",
    "        if better:\n",
    "            cur_step = 0\n",
    "            best = value\n",
    "            update_flag = True\n",
    "        else:\n",
    "            cur_step += 1\n",
    "            if cur_step > max_step:\n",
    "                stop_flag = True\n",
    "        return best, cur_step, stop_flag, update_flag\n",
    "\n",
    "    def _check_nan(self, loss):\n",
    "        if torch.isnan(loss).any():\n",
    "            raise ValueError(\"Model diverged with loss = NaN\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:16:14,661 - INFO - Initializing Model Based on path: /media/wuyuhuan/bge-small-zh\n",
      "2025-01-21 17:16:15,722 - INFO - Trainable Params: 168225. Total Params: 24122145. Trainable Paramaters Ratio: 0.006973882297780732\n",
      "Epoch 0 Train: 100%|██████████| 16/16 [00:06<00:00,  2.35it/s, loss: 0.3657 | forward: 9.96 ms | loss: 0.65 ms | backward: 56.71 ms] \n",
      "Epoch 0 Valid: 100%|██████████| 3/3 [00:01<00:00,  2.70it/s, loss=0.525]\n",
      "2025-01-21 17:16:23,758 - INFO - Epoch 0 Train mean Loss: 0.5671, Valid mean Loss: 0.5577\n",
      "2025-01-21 17:16:23,759 - INFO - Epoch 1 starts early stopping check.\n",
      "Epoch 1 Train: 100%|██████████| 16/16 [00:07<00:00,  2.18it/s, loss: 0.6383 | forward: 8.62 ms | loss: 0.00 ms | backward: 14.10 ms]  \n",
      "Epoch 1 Valid: 100%|██████████| 3/3 [00:00<00:00,  3.09it/s, loss=0.528]\n",
      "2025-01-21 17:16:32,079 - INFO - Epoch 1 Train mean Loss: 0.5624, Valid mean Loss: 0.5524\n",
      "2025-01-21 17:16:32,080 - INFO - Epoch 2 starts early stopping check.\n",
      "Epoch 2 Train: 100%|██████████| 16/16 [00:04<00:00,  3.26it/s, loss: 0.6296 | forward: 8.48 ms | loss: 0.00 ms | backward: 14.48 ms] \n",
      "Epoch 2 Valid: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s, loss=0.526]\n",
      "2025-01-21 17:16:38,394 - INFO - Epoch 2 Train mean Loss: 0.5605, Valid mean Loss: 0.5521\n",
      "2025-01-21 17:16:38,395 - INFO - Epoch 3 starts early stopping check.\n",
      "Epoch 3 Train: 100%|██████████| 16/16 [00:04<00:00,  3.23it/s, loss: 0.5611 | forward: 9.33 ms | loss: 0.00 ms | backward: 13.03 ms] \n",
      "Epoch 3 Valid: 100%|██████████| 3/3 [00:01<00:00,  2.96it/s, loss=0.527]\n",
      "2025-01-21 17:16:44,368 - INFO - Epoch 3 Train mean Loss: 0.5551, Valid mean Loss: 0.5528\n",
      "2025-01-21 17:16:44,369 - INFO - Epoch 4 starts early stopping check.\n",
      "Epoch 4 Train: 100%|██████████| 16/16 [00:04<00:00,  3.23it/s, loss: 0.5707 | forward: 11.29 ms | loss: 0.00 ms | backward: 12.30 ms]\n",
      "Epoch 4 Valid: 100%|██████████| 3/3 [00:00<00:00,  3.05it/s, loss=0.524]\n",
      "2025-01-21 17:16:50,319 - INFO - Epoch 4 Train mean Loss: 0.5553, Valid mean Loss: 0.5534\n",
      "2025-01-21 17:16:50,319 - INFO - Epoch 5 starts early stopping check.\n",
      "Epoch 5 Train: 100%|██████████| 16/16 [00:04<00:00,  3.24it/s, loss: 0.5345 | forward: 11.74 ms | loss: 0.00 ms | backward: 13.92 ms]\n",
      "Epoch 5 Valid: 100%|██████████| 3/3 [00:00<00:00,  3.01it/s, loss=0.526]\n",
      "2025-01-21 17:16:56,262 - INFO - Epoch 5 Train mean Loss: 0.5532, Valid mean Loss: 0.5534\n",
      "2025-01-21 17:16:56,263 - INFO - Epoch 6 starts early stopping check.\n",
      "Epoch 6 Train: 100%|██████████| 16/16 [00:04<00:00,  3.21it/s, loss: 0.6463 | forward: 12.18 ms | loss: 0.00 ms | backward: 13.41 ms]\n",
      "Epoch 6 Valid: 100%|██████████| 3/3 [00:00<00:00,  3.20it/s, loss=0.527]\n",
      "2025-01-21 17:17:02,201 - INFO - Epoch 6 Train mean Loss: 0.5574, Valid mean Loss: 0.5542\n",
      "2025-01-21 17:17:02,201 - INFO - Epoch 7 starts early stopping check.\n",
      "Epoch 7 Train: 100%|██████████| 16/16 [00:04<00:00,  3.25it/s, loss: 0.4875 | forward: 8.55 ms | loss: 0.84 ms | backward: 13.74 ms] \n",
      "Epoch 7 Valid: 100%|██████████| 3/3 [00:00<00:00,  3.24it/s, loss=0.526]\n",
      "2025-01-21 17:17:08,065 - INFO - Epoch 7 Train mean Loss: 0.5495, Valid mean Loss: 0.5546\n",
      "2025-01-21 17:17:08,066 - INFO - Epoch 8 starts early stopping check.\n",
      "Epoch 8 Train: 100%|██████████| 16/16 [00:05<00:00,  3.07it/s, loss: 0.5554 | forward: 10.20 ms | loss: 0.00 ms | backward: 15.67 ms]\n",
      "Epoch 8 Valid: 100%|██████████| 3/3 [00:00<00:00,  3.25it/s, loss=0.528]\n",
      "2025-01-21 17:17:14,205 - INFO - Epoch 8 Train mean Loss: 0.5522, Valid mean Loss: 0.5550\n",
      "2025-01-21 17:17:14,205 - INFO - Epoch 9 starts early stopping check.\n",
      "2025-01-21 17:17:14,206 - INFO - Early stopping at epoch 8\n",
      "2025-01-21 17:17:14,207 - INFO - Start evaluating on test set\n",
      "Matrices Evaluation     : 100%|██████████| 3/3 [00:00<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model = BGE_FTModel(bge_path).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.BCELoss()\n",
    "trainer = Trainer(model, train_loader, valid_loader, test_loader, optimizer, eval_step=1)\n",
    "best_valid = trainer.train(epochs = 50)\n",
    "evaluator = Evaluator()\n",
    "result, result_str = trainer.eval(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.4416666666666667,\n",
       " 'logloss': 17.270917248951967,\n",
       " 'ndcg@1': 0.19636363636363635,\n",
       " 'ndcg@5': 0.20976689851956432,\n",
       " 'ndcg@10': 0.20976689851956432,\n",
       " 'precision@1': 0.19636363636363635,\n",
       " 'precision@5': 0.19924242424242422,\n",
       " 'precision@10': 0.19924242424242422,\n",
       " 'recall@1': 0.8916666666666667,\n",
       " 'recall@5': 1.0,\n",
       " 'recall@10': 1.0,\n",
       " 'map@1': 0.19636363636363635,\n",
       " 'map@5': 0.20681818181818182,\n",
       " 'map@10': 0.20681818181818182,\n",
       " 'mrr@1': 0.20666666666666664,\n",
       " 'mrr@5': 0.20666666666666664,\n",
       " 'mrr@10': 0.20666666666666664}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BGE_FTDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m BGE_FTDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/processed_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer,ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m BGE_FTDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/processed_valid.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer,ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m BGE_FTDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/processed_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BGE_FTDataset' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dataset = BGE_FTDataset('train', 'dataset/processed_train.csv', tokenizer,ratio=1)\n",
    "valid_dataset = BGE_FTDataset('valid', \"dataset/processed_valid.csv\", tokenizer,ratio=1)\n",
    "test_dataset = BGE_FTDataset('test', \"dataset/processed_test.csv\", tokenizer, ratio=1)\n",
    "\n",
    "def save_tokenized_dataset_to_json(dataset, output_file):\n",
    "    \"\"\"\n",
    "    将 IterableDataset 的 tokenized 文本逐条存储到 JSON 文件中。\n",
    "\n",
    "    Args:\n",
    "        dataset (IterableDataset): 实现了 __iter__ 方法的 dataset，如 BGE_FTDataset。\n",
    "        output_file (str): 要保存的 JSON 文件路径。\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in tqdm(dataset, desc=\"Saving tokenized dataset to JSON\"):\n",
    "            # 将 PyTorch 张量转换为可序列化的格式\n",
    "            serialized_sample = {\n",
    "                \"user_id\": sample[\"user_id\"],  # 字符串或基本数据类型，直接存储\n",
    "                \"job_id\": sample[\"job_id\"],    # 字符串或基本数据类型，直接存储\n",
    "                \"model_input\": {\n",
    "                    \"model_input_cv\": {\n",
    "                        k: v.tolist() for k, v in sample[\"model_input\"][\"model_input_cv\"].items()\n",
    "                    },\n",
    "                    \"model_input_jd\": {\n",
    "                        k: v.tolist() for k, v in sample[\"model_input\"][\"model_input_jd\"].items()\n",
    "                    },\n",
    "                    \"label\": sample[\"model_input\"][\"label\"].item()  # 转为 float\n",
    "                }\n",
    "            }\n",
    "            # 将该样本写入 JSON 文件，每行一个样本\n",
    "            f.write(json.dumps(serialized_sample) + '\\n')\n",
    "\n",
    "train_dataset = BGE_FTDataset('train', 'dataset/processed_train.csv', tokenizer,ratio=1)\n",
    "valid_dataset = BGE_FTDataset('valid', \"dataset/processed_valid.csv\", tokenizer,ratio=1)\n",
    "test_dataset = BGE_FTDataset('test', \"dataset/processed_test.csv\", tokenizer, ratio=1)\n",
    "\n",
    "save_tokenized_dataset_to_json(train_dataset, '/media/wuyuhuan/tokenids/train_token_jsons.json')\n",
    "save_tokenized_dataset_to_json(valid_dataset, '/media/wuyuhuan/tokenids/valid_token_jsons.json')\n",
    "save_tokenized_dataset_to_json(test_dataset, '/media/wuyuhuan/tokenids/test_token_jsons.json')\n",
    "# 示例用法\n",
    "# 假设你已经定义了 BGE_FTDataset\n",
    "# dataset = BGE_FTDataset(mode='train', in_file='path/to/input.csv', tokenizer=your_tokenizer)\n",
    "# save_tokenized_dataset_to_json(dataset, output_file='output.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5313714494507185,\n",
       " 'logloss': 0.5764790056676369,\n",
       " 'ndcg@1': 0.2520190023752969,\n",
       " 'ndcg@5': 0.4664345684607033,\n",
       " 'ndcg@10': 0.5028075114044772,\n",
       " 'precision@1': 0.2520190023752969,\n",
       " 'precision@5': 0.24563737133808594,\n",
       " 'precision@10': 0.2415688270557644,\n",
       " 'recall@1': 0.13997698901130962,\n",
       " 'recall@5': 0.4863068289489413,\n",
       " 'recall@10': 0.7198235059496314,\n",
       " 'map@1': 0.2520190023752969,\n",
       " 'map@5': 0.38942564001055857,\n",
       " 'map@10': 0.38262279548927025,\n",
       " 'mrr@1': 0.4238476160112081,\n",
       " 'mrr@5': 0.4238476160112081,\n",
       " 'mrr@10': 0.4238476160112081}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
